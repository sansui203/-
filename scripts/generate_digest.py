#!/usr/bin/env python3
"""
AI èµ„è®¯èšåˆå™¨ - çƒ­åŠ è½½ç‰ˆæœ¬
æ¯ä¸ªæ•°æ®æºç‹¬ç«‹è¿è¡Œï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–
"""

import os
import json
import requests
import feedparser
from datetime import datetime, timedelta
from pathlib import Path


class AIDigestGenerator:
    def __init__(self):
        self.siliconflow_key = os.environ.get("SILICONFLOW_API_KEY")
        self.youtube_key = os.environ.get("YOUTUBE_API_KEY")
        self.twitter_key = os.environ.get("TWITTER_API_KEY")
        self.rapidapi_key = os.environ.get("RAPIDAPI_KEY")
        
        self.model = os.environ.get("SILICONFLOW_MODEL", "deepseek-ai/DeepSeek-V3")
        
        self.today = datetime.now()
        self.today_str = self.today.strftime("%Y-%m-%d")
        self.yesterday = self.today - timedelta(days=1)
        
        self.data_dir = Path("data")
        self.data_dir.mkdir(exist_ok=True)
        
        self.all_items = []
        
        # æ‰“å° API çŠ¶æ€
        print("ğŸ“‹ API çŠ¶æ€:")
        print(f"  - ç¡…åŸºæµåŠ¨: {'âœ…' if self.siliconflow_key else 'âŒ æœªé…ç½®'}")
        print(f"  - YouTube: {'âœ…' if self.youtube_key else 'âš ï¸ è·³è¿‡'}")
        print(f"  - Twitter: {'âœ…' if self.twitter_key else 'âš ï¸ è·³è¿‡'}")
        print(f"  - TikTok: {'âœ…' if self.rapidapi_key else 'âš ï¸ è·³è¿‡'}")

    def safe_fetch(self, name, func):
        """å®‰å…¨æ‰§è¡Œæ•°æ®è·å–ï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–"""
        try:
            func()
        except Exception as e:
            print(f"  âŒ {name} å¤±è´¥: {e}")

    # ==================== RSSï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_rss(self):
        """è·å– RSS æ–°é—»"""
        print("\nğŸ“° RSS æ–°é—»...")
        
        sources = [
            ("https://www.nytimes.com/svc/collections/v1/publish/https://www.nytimes.com/spotlight/artificial-intelligence/rss.xml", "çº½çº¦æ—¶æŠ¥"),
            ("https://techcrunch.com/category/artificial-intelligence/feed/", "TechCrunch"),
            ("https://www.theverge.com/rss/ai-artificial-intelligence/index.xml", "The Verge"),
        ]
        
        for url, name in sources:
            try:
                feed = feedparser.parse(url)
                count = 0
                for entry in feed.entries[:10]:
                    pub = entry.get("published_parsed") or entry.get("updated_parsed")
                    if pub:
                        dt = datetime(*pub[:6])
                        if dt > self.yesterday:
                            self.all_items.append({
                                "æ ‡é¢˜": entry.get("title", ""),
                                "å†…å®¹": entry.get("summary", "")[:200],
                                "æ—¥æœŸ": dt.isoformat(),
                                "æ¥æº": name,
                                "æ¿å—": "æ–°é—»",
                                "é“¾æ¥": entry.get("link", "")
                            })
                            count += 1
                print(f"  âœ… {name}: {count} æ¡")
            except Exception as e:
                print(f"  âŒ {name}: {e}")

    # ==================== YouTube åšä¸»ï¼ˆRSSï¼Œæ— éœ€ APIï¼‰====================
    
    def fetch_youtube_rss(self):
        """è·å– YouTube åšä¸»æ›´æ–°"""
        print("\nğŸ“º YouTube åšä¸»...")
        
        channels = [
            "UCNJ1Ymd5yFuUPtn21xtRbbw",
            "UChpleBmo18P08aKCIgti38g", 
            "UCPjNBjflYl0-HQtUvOx0Ibw"
        ]
        
        for cid in channels:
            try:
                feed = feedparser.parse(f"https://www.youtube.com/feeds/videos.xml?channel_id={cid}")
                name = feed.feed.get("author", "YouTube")
                count = 0
                for entry in feed.entries[:3]:
                    pub = entry.get("published_parsed")
                    if pub:
                        dt = datetime(*pub[:6])
                        if dt > self.yesterday:
                            self.all_items.append({
                                "æ ‡é¢˜": entry.get("title", ""),
                                "å†…å®¹": "",
                                "æ—¥æœŸ": dt.isoformat(),
                                "æ¥æº": name,
                                "æ¿å—": "æ²¹ç®¡åšä¸»",
                                "é“¾æ¥": entry.get("link", "")
                            })
                            count += 1
                print(f"  âœ… {name}: {count} æ¡")
            except Exception as e:
                print(f"  âŒ é¢‘é“ {cid[:8]}: {e}")

    # ==================== YouTube çƒ­é—¨ï¼ˆéœ€è¦ APIï¼‰====================
    
    def fetch_youtube_trending(self):
        """è·å– YouTube çƒ­é—¨è§†é¢‘"""
        if not self.youtube_key:
            return
        
        print("\nğŸ”¥ YouTube çƒ­é—¨...")
        
        try:
            # æœç´¢
            r = requests.get("https://www.googleapis.com/youtube/v3/search", params={
                "key": self.youtube_key,
                "part": "snippet",
                "q": "AI",
                "order": "relevance",
                "maxResults": 50,
                "regionCode": "US",
                "type": "video",
                "publishedAfter": self.yesterday.isoformat() + "Z"
            }, timeout=30)
            data = r.json()
            
            if "items" not in data:
                print(f"  âŒ {data.get('error', {}).get('message', 'é”™è¯¯')}")
                return
            
            ids = [i["id"]["videoId"] for i in data["items"]]
            
            # ç»Ÿè®¡
            r2 = requests.get("https://www.googleapis.com/youtube/v3/videos", params={
                "key": self.youtube_key,
                "part": "statistics",
                "id": ",".join(ids)
            }, timeout=30)
            stats = {i["id"]: i["statistics"] for i in r2.json().get("items", [])}
            
            count = 0
            for item in data["items"]:
                vid = item["id"]["videoId"]
                views = int(stats.get(vid, {}).get("viewCount", 0))
                if views > 200000:
                    self.all_items.append({
                        "æ ‡é¢˜": item["snippet"]["title"],
                        "å†…å®¹": item["snippet"]["description"][:150],
                        "æ—¥æœŸ": item["snippet"]["publishTime"],
                        "æ¥æº": "YouTube",
                        "æ¿å—": "YouTubeçƒ­ç‚¹",
                        "é“¾æ¥": f"https://youtube.com/watch?v={vid}"
                    })
                    count += 1
            print(f"  âœ… {count} æ¡ (æ’­æ”¾é‡>20ä¸‡)")
        except Exception as e:
            print(f"  âŒ {e}")

    # ==================== Twitterï¼ˆéœ€è¦ APIï¼‰====================
    
    def fetch_twitter(self):
        """è·å– Twitter çƒ­é—¨"""
        if not self.twitter_key:
            return
        
        print("\nğŸ¦ Twitter çƒ­é—¨...")
        
        try:
            r = requests.get("https://api.twitterapi.io/twitter/tweet/advanced_search",
                headers={"x-api-key": self.twitter_key},
                params={"query": "AI", "queryType": "Top"},
                timeout=30)
            data = r.json()
            
            count = 0
            for t in data.get("tweets", []):
                views = t.get("viewCount", 0)
                heat = t.get("likeCount", 0) + t.get("retweetCount", 0) * 2
                if views > 10000 and heat > 1000:
                    self.all_items.append({
                        "æ ‡é¢˜": t.get("text", "")[:100],
                        "å†…å®¹": t.get("text", ""),
                        "æ—¥æœŸ": t.get("createdAt", ""),
                        "æ¥æº": "Twitter",
                        "æ¿å—": "Twitterçƒ­ç‚¹",
                        "é“¾æ¥": t.get("url", "")
                    })
                    count += 1
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {e}")

    def fetch_twitter_accounts(self):
        """è·å–æ˜æ˜Ÿå…¬å¸åŠ¨æ€"""
        if not self.twitter_key:
            return
        
        print("\nğŸŒŸ æ˜æ˜Ÿå…¬å¸åŠ¨æ€...")
        
        for user in ["OpenAI", "GoogleDeepMind", "GoogleAIStudio"]:
            try:
                r = requests.get("https://api.twitterapi.io/twitter/user/last_tweets",
                    headers={"x-api-key": self.twitter_key},
                    params={"userName": user},
                    timeout=30)
                data = r.json()
                
                count = 0
                for t in data.get("data", {}).get("tweets", [])[:5]:
                    text = t.get("text", "")
                    if t.get("retweeted_tweet"):
                        text = f"(è½¬å‘) {t['retweeted_tweet'].get('text', '')}"
                    self.all_items.append({
                        "æ ‡é¢˜": text[:100],
                        "å†…å®¹": text,
                        "æ—¥æœŸ": t.get("createdAt", ""),
                        "æ¥æº": user,
                        "æ¿å—": "æ˜æ˜Ÿå…¬å¸åŠ¨æ€",
                        "é“¾æ¥": t.get("url", "")
                    })
                    count += 1
                print(f"  âœ… @{user}: {count} æ¡")
            except Exception as e:
                print(f"  âŒ @{user}: {e}")

    # ==================== TikTokï¼ˆéœ€è¦ APIï¼‰====================
    
    def fetch_tiktok(self):
        """è·å– TikTok çƒ­é—¨"""
        if not self.rapidapi_key:
            return
        
        print("\nğŸµ TikTok çƒ­é—¨...")
        
        try:
            r = requests.get("https://tiktok-api23.p.rapidapi.com/api/search/general",
                headers={
                    "x-rapidapi-key": self.rapidapi_key,
                    "x-rapidapi-host": "tiktok-api23.p.rapidapi.com"
                },
                params={"keyword": "AI", "cursor": "0"},
                timeout=30)
            data = r.json()
            
            count = 0
            for item in data.get("data", []):
                d = item.get("item", {})
                plays = d.get("stats", {}).get("playCount", 0)
                followers = d.get("authorStats", {}).get("followerCount", 1)
                
                if plays > 100000 and plays / followers > 3:
                    ts = d.get("createTime", 0)
                    if ts and datetime.fromtimestamp(ts) > self.today - timedelta(days=14):
                        author = d.get("author", {})
                        self.all_items.append({
                            "æ ‡é¢˜": d.get("desc", "")[:100],
                            "å†…å®¹": d.get("desc", ""),
                            "æ—¥æœŸ": datetime.fromtimestamp(ts).isoformat(),
                            "æ¥æº": "TikTok",
                            "æ¿å—": "TikTokçƒ­ç‚¹",
                            "é“¾æ¥": f"https://tiktok.com/@{author.get('uniqueId', '')}/video/{d.get('id', '')}"
                        })
                        count += 1
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {e}")

    # ==================== GitHubï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_github_trending(self):
        """è·å– GitHub Trendingï¼ˆä½¿ç”¨ç¬¬ä¸‰æ–¹ APIï¼‰"""
        print("\nâ­ GitHub Trending...")
        
        periods = [
            ("daily", "ä»Šæ—¥çƒ­é—¨"),
            ("weekly", "æœ¬å‘¨çƒ­é—¨")
        ]
        
        for period, label in periods:
            try:
                # ä½¿ç”¨ GitHub Trending API
                r = requests.get(
                    f"https://api.gitterapp.com/repositories?since={period}",
                    headers={"User-Agent": "Mozilla/5.0"},
                    timeout=30
                )
                repos = r.json()
                
                count = 0
                for repo in repos[:15]:
                    author = repo.get("author", "")
                    name = repo.get("name", "")
                    desc = repo.get("description", "")
                    lang = repo.get("language", "Unknown")
                    stars = repo.get("stars", 0)
                    stars_today = repo.get("starsSince", 0)
                    
                    self.all_items.append({
                        "æ ‡é¢˜": f"{author}/{name}",
                        "å†…å®¹": desc[:200],
                        "æ—¥æœŸ": self.today.isoformat(),
                        "æ¥æº": f"GitHub {label}",
                        "æ¿å—": f"GitHub{label}",
                        "é“¾æ¥": repo.get("url", f"https://github.com/{author}/{name}"),
                        "é¢å¤–": f"â­ {stars:,} | ğŸ”¥ {period} +{stars_today:,} | ğŸ’» {lang}"
                    })
                    count += 1
                
                print(f"  âœ… {label}: {count} æ¡")
            except Exception as e:
                print(f"  âŒ {label}: {e}")

    # ==================== HuggingFaceï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_huggingface_trending(self):
        """è·å– HuggingFace çƒ­é—¨æ¨¡å‹"""
        print("\nğŸ¤— HuggingFace Trending...")
        
        try:
            # ä½¿ç”¨ HuggingFace API
            r = requests.get(
                "https://huggingface.co/api/models",
                params={
                    "sort": "trending",
                    "direction": -1,
                    "limit": 20
                },
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=30
            )
            models = r.json()
            
            count = 0
            for model in models[:15]:
                model_id = model.get("id", "")
                if not model_id:
                    continue
                    
                downloads = model.get("downloads", 0)
                likes = model.get("likes", 0)
                
                self.all_items.append({
                    "æ ‡é¢˜": model_id,
                    "å†…å®¹": model.get("description", "")[:150] or f"Pipeline: {model.get('pipeline_tag', 'N/A')}",
                    "æ—¥æœŸ": self.today.isoformat(),
                    "æ¥æº": "HuggingFace",
                    "æ¿å—": "HuggingFaceçƒ­é—¨",
                    "é“¾æ¥": f"https://huggingface.co/{model_id}",
                    "é¢å¤–": f"ğŸ“¥ {downloads:,} ä¸‹è½½ | â¤ï¸ {likes} ç‚¹èµ"
                })
                count += 1
            
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {e}")
    
    # ==================== ModelScopeï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_modelscope_trending(self):
        """è·å– ModelScope çƒ­é—¨æ¨¡å‹"""
        print("\nğŸ”® ModelScope Trending...")
        
        try:
            # ModelScope API (å¤šè¯•å‡ ä¸ªæ¥å£)
            endpoints = [
                ("https://www.modelscope.cn/api/v1/models", {"PageNumber": 1, "PageSize": 20, "SortBy": "gmtDownload7d"}),
                ("https://modelscope.cn/api/v1/models", {"PageNumber": 1, "PageSize": 20})
            ]
            
            for url, params in endpoints:
                try:
                    r = requests.get(url, params=params, 
                        headers={"User-Agent": "Mozilla/5.0"},
                        timeout=30)
                    data = r.json()
                    
                    models_data = data.get("Data", []) or data.get("data", [])
                    if not models_data:
                        continue
                    
                    count = 0
                    for model in models_data[:15]:
                        model_name = model.get("Path") or model.get("Name") or model.get("Id", "")
                        if not model_name:
                            continue
                            
                        desc = model.get("ChineseDescription") or model.get("Description", "")
                        downloads = model.get("Downloads", 0) or model.get("DownloadCount", 0)
                        
                        self.all_items.append({
                            "æ ‡é¢˜": model_name,
                            "å†…å®¹": desc[:150] if desc else "ModelScope çƒ­é—¨æ¨¡å‹",
                            "æ—¥æœŸ": self.today.isoformat(),
                            "æ¥æº": "ModelScope",
                            "æ¿å—": "ModelScopeçƒ­é—¨",
                            "é“¾æ¥": f"https://modelscope.cn/models/{model_name}",
                            "é¢å¤–": f"ğŸ“¥ {downloads:,} ä¸‹è½½"
                        })
                        count += 1
                    
                    print(f"  âœ… {count} æ¡")
                    return  # æˆåŠŸå°±é€€å‡º
                    
                except Exception as e:
                    continue
            
            print("  âš ï¸ æ‰€æœ‰æ¥å£å‡å¤±è´¥")
            
        except Exception as e:
            print(f"  âŒ {e}")

    # ==================== AI å¤„ç† ====================
    
    def ai_process(self):
        """AI ç¿»è¯‘å’Œæ‘˜è¦"""
        if not self.siliconflow_key:
            error_msg = "âŒ æœªé…ç½® SILICONFLOW_API_KEYï¼Œæ— æ³•è¿›è¡Œ AI å¤„ç†"
            print(f"\n{error_msg}")
            
            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            fallback = {
                "date": self.today_str,
                "error": error_msg,
                "categories": {"åŸå§‹æ•°æ®": self.all_items},
                "analysis": {
                    "summary": "âš ï¸ æœªé…ç½® API Keyï¼Œè¯·åœ¨ GitHub Secrets ä¸­æ·»åŠ  SILICONFLOW_API_KEY",
                    "trends": []
                }
            }
            (self.data_dir / "latest.json").write_text(
                json.dumps(fallback, ensure_ascii=False, indent=2), encoding="utf-8")
            return fallback
        
        if not self.all_items:
            print("\nâš ï¸ æ²¡æœ‰æ•°æ®")
            return None
        
        print(f"\nğŸ¤– AI å¤„ç† ({self.model})...")
        
        prompt = f"""å¤„ç†ä»¥ä¸‹AIèµ„è®¯ï¼Œè¾“å‡ºJSONï¼š

{json.dumps(self.all_items[:100], ensure_ascii=False)}

è¦æ±‚ï¼š
1. è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡
2. é•¿å†…å®¹ç”Ÿæˆ60-80å­—æ‘˜è¦  
3. æŒ‰æ¿å—åˆ†ç»„
4. ä¿ç•™"é¢å¤–"å­—æ®µï¼ˆæ˜Ÿæ ‡ã€ä¸‹è½½é‡ç­‰æ•°æ®ï¼‰

è¾“å‡ºæ ¼å¼ï¼š
{{"date":"{self.today_str}","categories":{{"æ–°é—»":[],"æ˜æ˜Ÿå…¬å¸åŠ¨æ€":[],"æ²¹ç®¡åšä¸»":[],"YouTubeçƒ­ç‚¹":[],"Twitterçƒ­ç‚¹":[],"TikTokçƒ­ç‚¹":[],"GitHubä»Šæ—¥çƒ­é—¨":[],"GitHubæœ¬å‘¨çƒ­é—¨":[],"HuggingFaceçƒ­é—¨":[],"ModelScopeçƒ­é—¨":[]}},"analysis":{{"summary":"ä»Šæ—¥æ‘˜è¦","trends":["è¶‹åŠ¿1","è¶‹åŠ¿2"]}}}}

åªè¾“å‡ºJSONã€‚"""

        try:
            from openai import OpenAI
            client = OpenAI(
                api_key=self.siliconflow_key,
                base_url="https://api.siliconflow.cn/v1"
            )
            
            resp = client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=8000
            )
            
            content = resp.choices[0].message.content
            if "```" in content:
                content = content.split("```")[1].replace("json", "").strip()
            
            result = json.loads(content)
            
            # ä¿å­˜
            (self.data_dir / f"digest_{self.today_str}.json").write_text(
                json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
            (self.data_dir / "latest.json").write_text(
                json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
            
            total = sum(len(v) for v in result.get("categories", {}).values())
            print(f"  âœ… å®Œæˆï¼Œå…± {total} æ¡")
            return result
            
        except Exception as e:
            import traceback
            error_msg = f"AI å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
            print(f"  âŒ {error_msg}")
            
            # å¤±è´¥æ—¶ä¿å­˜åŸå§‹æ•°æ®ï¼Œå¹¶é™„å¸¦é”™è¯¯ä¿¡æ¯
            fallback = {
                "date": self.today_str,
                "error": error_msg,
                "categories": {"åŸå§‹æ•°æ®": self.all_items},
                "analysis": {
                    "summary": f"âš ï¸ AI å¤„ç†å¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹æ•°æ®ã€‚é”™è¯¯ï¼š{str(e)}",
                    "trends": []
                }
            }
            (self.data_dir / "latest.json").write_text(
                json.dumps(fallback, ensure_ascii=False, indent=2), encoding="utf-8")
            return fallback

    def run(self):
        print("=" * 50)
        print(f"ğŸš€ AI èµ„è®¯èšåˆå™¨ - {self.today_str}")
        print("=" * 50)
        
        # æ•°æ®é‡‡é›†ï¼ˆæ¯ä¸ªç‹¬ç«‹ï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–ï¼‰
        self.safe_fetch("RSS", self.fetch_rss)
        self.safe_fetch("YouTubeåšä¸»", self.fetch_youtube_rss)
        self.safe_fetch("YouTubeçƒ­é—¨", self.fetch_youtube_trending)
        self.safe_fetch("Twitterçƒ­é—¨", self.fetch_twitter)
        self.safe_fetch("Twitterè´¦å·", self.fetch_twitter_accounts)
        self.safe_fetch("TikTok", self.fetch_tiktok)
        self.safe_fetch("GitHubçƒ­é—¨", self.fetch_github_trending)
        self.safe_fetch("HuggingFace", self.fetch_huggingface_trending)
        self.safe_fetch("ModelScope", self.fetch_modelscope_trending)
        
        print(f"\nğŸ“¦ å…±é‡‡é›† {len(self.all_items)} æ¡")
        
        # AI å¤„ç†
        result = self.ai_process()
        
        print("\n" + "=" * 50)
        print("âœ¨ å®Œæˆ!")
        return result


if __name__ == "__main__":
    AIDigestGenerator().run()
