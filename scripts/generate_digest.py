#!/usr/bin/env python3
"""
AI èµ„è®¯èšåˆå™¨ - çƒ­åŠ è½½ç‰ˆæœ¬
æ¯ä¸ªæ•°æ®æºç‹¬ç«‹è¿è¡Œï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–
"""

import os
import json
import requests
import feedparser
from datetime import datetime, timedelta
from pathlib import Path


class AIDigestGenerator:
    def __init__(self):
        self.siliconflow_key = os.environ.get("SILICONFLOW_API_KEY")
        self.youtube_key = os.environ.get("YOUTUBE_API_KEY")
        self.twitter_key = os.environ.get("TWITTER_API_KEY")
        self.rapidapi_key = os.environ.get("RAPIDAPI_KEY")
        
        self.model = os.environ.get("SILICONFLOW_MODEL", "deepseek-ai/DeepSeek-V3")
        
        self.today = datetime.now()
        self.today_str = self.today.strftime("%Y-%m-%d")
        self.yesterday = self.today - timedelta(days=1)
        
        self.data_dir = Path("data")
        self.data_dir.mkdir(exist_ok=True)
        
        self.all_items = []
        
        # æ‰“å° API çŠ¶æ€
        print("ğŸ“‹ API çŠ¶æ€:")
        print(f"  - ç¡…åŸºæµåŠ¨: {'âœ…' if self.siliconflow_key else 'âŒ æœªé…ç½®'}")
        print(f"  - YouTube: {'âœ…' if self.youtube_key else 'âš ï¸ è·³è¿‡'}")
        print(f"  - Twitter: {'âœ…' if self.twitter_key else 'âš ï¸ è·³è¿‡'}")
        print(f"  - TikTok: {'âœ…' if self.rapidapi_key else 'âš ï¸ è·³è¿‡'}")

    def safe_fetch(self, name, func):
        """å®‰å…¨æ‰§è¡Œæ•°æ®è·å–ï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–"""
        try:
            func()
        except Exception as e:
            print(f"  âŒ {name} å¤±è´¥: {e}")

    # ==================== RSSï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_rss(self):
        """è·å– RSS æ–°é—»"""
        print("\nğŸ“° RSS æ–°é—»...")
        
        sources = [
            ("https://www.nytimes.com/svc/collections/v1/publish/https://www.nytimes.com/spotlight/artificial-intelligence/rss.xml", "çº½çº¦æ—¶æŠ¥"),
            ("https://techcrunch.com/category/artificial-intelligence/feed/", "TechCrunch"),
            ("https://www.theverge.com/rss/ai-artificial-intelligence/index.xml", "The Verge"),
        ]
        
        for url, name in sources:
            try:
                feed = feedparser.parse(url)
                count = 0
                for entry in feed.entries[:10]:
                    pub = entry.get("published_parsed") or entry.get("updated_parsed")
                    if pub:
                        dt = datetime(*pub[:6])
                        if dt > self.yesterday:
                            self.all_items.append({
                                "æ ‡é¢˜": entry.get("title", ""),
                                "å†…å®¹": entry.get("summary", "")[:200],
                                "æ—¥æœŸ": dt.isoformat(),
                                "æ¥æº": name,
                                "æ¿å—": "æ–°é—»",
                                "é“¾æ¥": entry.get("link", "")
                            })
                            count += 1
                print(f"  âœ… {name}: {count} æ¡")
            except Exception as e:
                print(f"  âŒ {name}: {e}")

    # ==================== YouTube åšä¸»ï¼ˆRSSï¼Œæ— éœ€ APIï¼‰====================
    
    def fetch_youtube_rss(self):
        """è·å– YouTube åšä¸»æ›´æ–°"""
        print("\nğŸ“º YouTube åšä¸»...")
        
        channels = [
            "UCNJ1Ymd5yFuUPtn21xtRbbw",
            "UChpleBmo18P08aKCIgti38g", 
            "UCPjNBjflYl0-HQtUvOx0Ibw"
        ]
        
        for cid in channels:
            try:
                feed = feedparser.parse(f"https://www.youtube.com/feeds/videos.xml?channel_id={cid}")
                name = feed.feed.get("author", "YouTube")
                count = 0
                for entry in feed.entries[:3]:
                    pub = entry.get("published_parsed")
                    if pub:
                        dt = datetime(*pub[:6])
                        if dt > self.yesterday:
                            self.all_items.append({
                                "æ ‡é¢˜": entry.get("title", ""),
                                "å†…å®¹": "",
                                "æ—¥æœŸ": dt.isoformat(),
                                "æ¥æº": name,
                                "æ¿å—": "æ²¹ç®¡åšä¸»",
                                "é“¾æ¥": entry.get("link", "")
                            })
                            count += 1
                print(f"  âœ… {name}: {count} æ¡")
            except Exception as e:
                print(f"  âŒ é¢‘é“ {cid[:8]}: {e}")

    # ==================== YouTube çƒ­é—¨ï¼ˆéœ€è¦ APIï¼‰====================
    
    def fetch_youtube_trending(self):
        """è·å– YouTube çƒ­é—¨è§†é¢‘"""
        if not self.youtube_key:
            return
        
        print("\nğŸ”¥ YouTube çƒ­é—¨...")
        
        try:
            # æœç´¢
            r = requests.get("https://www.googleapis.com/youtube/v3/search", params={
                "key": self.youtube_key,
                "part": "snippet",
                "q": "AI",
                "order": "relevance",
                "maxResults": 10,
                "regionCode": "US",
                "type": "video",
                "publishedAfter": self.yesterday.isoformat() + "Z"
            }, timeout=30)
            data = r.json()
            
            if "items" not in data:
                print(f"  âŒ {data.get('error', {}).get('message', 'é”™è¯¯')}")
                return
            
            ids = [i["id"]["videoId"] for i in data["items"]]
            
            # ç»Ÿè®¡
            r2 = requests.get("https://www.googleapis.com/youtube/v3/videos", params={
                "key": self.youtube_key,
                "part": "statistics",
                "id": ",".join(ids)
            }, timeout=30)
            stats = {i["id"]: i["statistics"] for i in r2.json().get("items", [])}
            
            count = 0
            for item in data["items"]:
                vid = item["id"]["videoId"]
                views = int(stats.get(vid, {}).get("viewCount", 0))
                if views > 200000:
                    self.all_items.append({
                        "æ ‡é¢˜": item["snippet"]["title"],
                        "å†…å®¹": item["snippet"]["description"][:150],
                        "æ—¥æœŸ": item["snippet"]["publishTime"],
                        "æ¥æº": "YouTube",
                        "æ¿å—": "YouTubeçƒ­ç‚¹",
                        "é“¾æ¥": f"https://youtube.com/watch?v={vid}"
                    })
                    count += 1
            print(f"  âœ… {count} æ¡ (æ’­æ”¾é‡>20ä¸‡)")
        except Exception as e:
            print(f"  âŒ {e}")

    # ==================== Twitterï¼ˆéœ€è¦ APIï¼‰====================
    
    def fetch_twitter(self):
        """è·å– Twitter çƒ­é—¨"""
        if not self.twitter_key:
            return
        
        print("\nğŸ¦ Twitter çƒ­é—¨...")
        
        try:
            r = requests.get("https://api.twitterapi.io/twitter/tweet/advanced_search",
                headers={"x-api-key": self.twitter_key},
                params={"query": "AI", "queryType": "Top"},
                timeout=30)
            data = r.json()
            
            count = 0
            for t in data.get("tweets", []):
                views = t.get("viewCount", 0)
                heat = t.get("likeCount", 0) + t.get("retweetCount", 0) * 2
                if views > 10000 and heat > 1000:
                    self.all_items.append({
                        "æ ‡é¢˜": t.get("text", "")[:100],
                        "å†…å®¹": t.get("text", ""),
                        "æ—¥æœŸ": t.get("createdAt", ""),
                        "æ¥æº": "Twitter",
                        "æ¿å—": "Twitterçƒ­ç‚¹",
                        "é“¾æ¥": t.get("url", "")
                    })
                    count += 1
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {e}")

    def fetch_twitter_accounts(self):
        """è·å–æ˜æ˜Ÿå…¬å¸åŠ¨æ€"""
        if not self.twitter_key:
            return
        
        print("\nğŸŒŸ æ˜æ˜Ÿå…¬å¸åŠ¨æ€...")
        
        for user in ["OpenAI", "GoogleDeepMind", "GoogleAIStudio"]:
            try:
                r = requests.get("https://api.twitterapi.io/twitter/user/last_tweets",
                    headers={"x-api-key": self.twitter_key},
                    params={"userName": user},
                    timeout=30)
                data = r.json()
                
                count = 0
                for t in data.get("data", {}).get("tweets", [])[:5]:
                    text = t.get("text", "")
                    if t.get("retweeted_tweet"):
                        text = f"(è½¬å‘) {t['retweeted_tweet'].get('text', '')}"
                    self.all_items.append({
                        "æ ‡é¢˜": text[:100],
                        "å†…å®¹": text,
                        "æ—¥æœŸ": t.get("createdAt", ""),
                        "æ¥æº": user,
                        "æ¿å—": "æ˜æ˜Ÿå…¬å¸åŠ¨æ€",
                        "é“¾æ¥": t.get("url", "")
                    })
                    count += 1
                print(f"  âœ… @{user}: {count} æ¡")
            except Exception as e:
                print(f"  âŒ @{user}: {e}")

    # ==================== TikTokï¼ˆéœ€è¦ APIï¼‰====================
    
    def fetch_tiktok(self):
        """è·å– TikTok çƒ­é—¨"""
        if not self.rapidapi_key:
            return
        
        print("\nğŸµ TikTok çƒ­é—¨...")
        
        try:
            r = requests.get("https://tiktok-api23.p.rapidapi.com/api/search/general",
                headers={
                    "x-rapidapi-key": self.rapidapi_key,
                    "x-rapidapi-host": "tiktok-api23.p.rapidapi.com"
                },
                params={"keyword": "AI", "cursor": "0"},
                timeout=30)
            data = r.json()
            
            count = 0
            for item in data.get("data", []):
                d = item.get("item", {})
                plays = d.get("stats", {}).get("playCount", 0)
                followers = d.get("authorStats", {}).get("followerCount", 1)
                
                if plays > 100000 and plays / followers > 3:
                    ts = d.get("createTime", 0)
                    if ts and datetime.fromtimestamp(ts) > self.today - timedelta(days=14):
                        author = d.get("author", {})
                        self.all_items.append({
                            "æ ‡é¢˜": d.get("desc", "")[:100],
                            "å†…å®¹": d.get("desc", ""),
                            "æ—¥æœŸ": datetime.fromtimestamp(ts).isoformat(),
                            "æ¥æº": "TikTok",
                            "æ¿å—": "TikTokçƒ­ç‚¹",
                            "é“¾æ¥": f"https://tiktok.com/@{author.get('uniqueId', '')}/video/{d.get('id', '')}"
                        })
                        count += 1
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {e}")

    # ==================== GitHubï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_github_trending(self):
        """è·å– GitHub Trendingï¼ˆå¤šä¸ªå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print("\nâ­ GitHub Trending...")
        
        periods = [
            ("daily", "ä»Šæ—¥çƒ­é—¨"),
            ("weekly", "æœ¬å‘¨çƒ­é—¨")
        ]
        
        for period, label in periods:
            count = 0
            
            # æ–¹æ¡ˆ1: å°è¯•å¤šä¸ª Trending API
            # GitHub Search API å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥è¯¢æœ€è¿‘æ´»è·ƒçš„é«˜æ˜Ÿé¡¹ç›®
            if period == "daily":
                # ä»Šæ—¥ï¼šæœ€è¿‘ 1 å¤©æ›´æ–°çš„é¡¹ç›®ï¼Œstar > 1000
                date_range = self.yesterday.strftime('%Y-%m-%d')
                stars_req = "1000"
                search_field = "pushed"  # ä½¿ç”¨ pushedï¼ˆæœ€è¿‘æ›´æ–°ï¼‰è€Œä¸æ˜¯ created
            else:
                # æœ¬å‘¨ï¼šæœ€è¿‘ 7 å¤©æ›´æ–°çš„é¡¹ç›®ï¼Œstar > 500
                date_range = (self.today - timedelta(days=7)).strftime('%Y-%m-%d')
                stars_req = "500"
                search_field = "pushed"
            
            apis = [
                f"https://api.gitterapp.com/repositories?since={period}",
                f"https://gh-trending-api.herokuapp.com/repositories?since={period}",
                f"https://api.github.com/search/repositories?q=stars:>{stars_req}+{search_field}:>{date_range}&sort=stars&order=desc&per_page=10",
            ]
            
            for api_url in apis:
                try:
                    headers = {"User-Agent": "Mozilla/5.0"}
                    r = requests.get(api_url, headers=headers, timeout=30)
                    if r.status_code != 200:
                        print(f"      âš ï¸ {api_url[:50]}... -> HTTP {r.status_code}")
                        continue
                    
                    data = r.json()
                    
                    # GitHub Search API è¿”å›æ ¼å¼ä¸åŒ
                    if "items" in data:
                        repos = data["items"]
                    else:
                        repos = data if isinstance(data, list) else []
                    
                    if not repos:
                        print(f"      âš ï¸ {api_url[:50]}... -> è¿”å›ç©ºæ•°æ®")
                        continue
                    
                    for repo in repos[:10]:
                        # å…¼å®¹å¤šç§ API è¿”å›æ ¼å¼
                        if "full_name" in repo:  # GitHub Search API
                            author, name = repo["full_name"].split("/") if "/" in repo["full_name"] else ("", repo["full_name"])
                        else:  # Trending API
                            author = repo.get("author", "") or repo.get("username", "")
                            name = repo.get("name", "") or repo.get("reponame", "")
                        
                        if not author or not name:
                            continue
                            
                        desc = repo.get("description", "") or ""
                        lang = repo.get("language", "") or repo.get("programmingLanguage", "") or "Unknown"
                        
                        # æ˜Ÿæ ‡æ•°
                        stars = (
                            repo.get("stars") or 
                            repo.get("totalStars") or 
                            repo.get("stargazers_count") or 
                            0
                        )
                        stars_today = repo.get("starsSince", 0) or repo.get("starsToday", 0)
                        
                        self.all_items.append({
                            "æ ‡é¢˜": f"{author}/{name}",
                            "å†…å®¹": desc[:200] if desc else f"{lang} é¡¹ç›®",
                            "æ—¥æœŸ": self.today.isoformat(),
                            "æ¥æº": f"GitHub {label}",
                            "æ¿å—": f"GitHub{label}",
                            "é“¾æ¥": repo.get("url") or repo.get("html_url") or f"https://github.com/{author}/{name}",
                            "é¢å¤–": f"â­ {stars:,} | ğŸ”¥ +{stars_today:,} | ğŸ’» {lang}" if stars_today else f"â­ {stars:,} | ğŸ’» {lang}"
                        })
                        count += 1
                    
                    if count > 0:
                        print(f"  âœ… {label}: {count} æ¡ï¼ˆä½¿ç”¨ {api_url.split('/')[2]}ï¼‰")
                        break  # æˆåŠŸå°±ä¸å°è¯•ä¸‹ä¸€ä¸ª API
                        
                except Exception as e:
                    print(f"      âŒ {api_url[:50]}... -> {type(e).__name__}: {str(e)[:100]}")
                    continue
            
            if count == 0:
                print(f"  âš ï¸ {label}: æ‰€æœ‰ API å‡å¤±è´¥")

    # ==================== HuggingFaceï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_huggingface_trending(self):
        """è·å– HuggingFace çƒ­é—¨æ¨¡å‹ï¼ˆå·²éªŒè¯å¯ç”¨ï¼‰"""
        print("\nğŸ¤— HuggingFace Trending...")
        
        try:
            # ä½¿ç”¨ HuggingFace å®˜æ–¹ APIï¼ˆå®æµ‹å¯ç”¨ï¼‰
            r = requests.get(
                "https://huggingface.co/api/models",
                params={"limit": 10},  # æŒ‰ trendingScore é»˜è®¤æ’åº
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=30
            )
            
            if r.status_code != 200:
                print(f"  âŒ HTTP {r.status_code}: {r.text[:200]}")
                return
                
            models = r.json()
            if not isinstance(models, list):
                print(f"  âŒ è¿”å›æ ¼å¼é”™è¯¯")
                return
            
            count = 0
            for model in models[:10]:
                if not isinstance(model, dict):
                    continue
                    
                model_id = model.get("id", "")
                if not model_id:
                    continue
                    
                downloads = model.get("downloads", 0) or 0
                likes = model.get("likes", 0) or 0
                trending = model.get("trendingScore", 0) or 0
                
                # è·å–æ ‡ç­¾å’Œä»»åŠ¡ç±»å‹
                tags = model.get("tags", [])
                task = next((t for t in tags if not t.startswith(("license:", "region:", "arxiv:"))), "æ¨¡å‹")
                
                self.all_items.append({
                    "æ ‡é¢˜": model_id,
                    "å†…å®¹": f"{task} | çƒ­åº¦: {trending}",
                    "æ—¥æœŸ": self.today.isoformat(),
                    "æ¥æº": "HuggingFace",
                    "æ¿å—": "HuggingFaceçƒ­é—¨",
                    "é“¾æ¥": f"https://huggingface.co/{model_id}",
                    "é¢å¤–": f"ğŸ“¥ {downloads:,} ä¸‹è½½ | â¤ï¸ {likes} ç‚¹èµ | ğŸ”¥ çƒ­åº¦ {trending}"
                })
                count += 1
            
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {type(e).__name__}: {str(e)[:100]}")
    
    # ==================== ModelScopeï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_modelscope_trending(self):
        """è·å– ModelScope çƒ­é—¨æ¨¡å‹ï¼ˆAPI å·²éªŒè¯å¤±æ•ˆï¼Œæš‚æ—¶è·³è¿‡ï¼‰"""
        print("\nğŸ”® ModelScope Trending...")
        print("  âš ï¸ ModelScope API å·²åºŸå¼ƒï¼ˆå®æµ‹ 404ï¼‰ï¼Œè·³è¿‡æ­¤æ•°æ®æº")
        # æ³¨ï¼šç»å®æµ‹ https://modelscope.cn/api/v1/models è¿”å› 404
        # ModelScope å¯èƒ½éœ€è¦è®¤è¯æˆ– API å·²è¿ç§»
        return

    def _fetch_modelscope_old(self):
        """æ—§çš„ ModelScope è·å–ä»£ç ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä½œå‚è€ƒï¼‰"""
        for url, params in [("https://modelscope.cn/api/v1/models", {"PageSize": 10})]:
            try:
                r = requests.get(
                    url, 
                    params=params, 
                    headers={
                        "User-Agent": "Mozilla/5.0",
                        "Referer": "https://modelscope.cn/"
                    },
                    timeout=30
                )
                
                if r.status_code != 200:
                    print(f"      âš ï¸ {url.split('/')[2]} -> HTTP {r.status_code}")
                    continue
                
                data = r.json()
                
                # å°è¯•å¤šç§æ•°æ®ç»“æ„
                models_data = (
                    data.get("Data") or 
                    data.get("data") or 
                    data.get("models") or 
                    []
                )
                
                if not models_data or not isinstance(models_data, list):
                    print(f"      âš ï¸ {url.split('/')[2]} -> è¿”å›æ•°æ®æ ¼å¼é”™è¯¯æˆ–ä¸ºç©º")
                    continue
                
                count = 0
                for model in models_data[:8]:
                    if not isinstance(model, dict):
                        continue
                    
                    # å¤šç§å­—æ®µåå°è¯•
                    model_name = (
                        model.get("Path") or 
                        model.get("Name") or 
                        model.get("Id") or 
                        model.get("ModelId") or
                        ""
                    )
                    
                    if not model_name:
                        continue
                    
                    desc = model.get("ChineseDescription") or model.get("Description", "")
                    if desc and isinstance(desc, str):
                        desc = desc[:150]
                    else:
                        desc = "ModelScope çƒ­é—¨æ¨¡å‹"
                    
                    downloads = model.get("Downloads", 0) or model.get("DownloadCount", 0) or 0
                    
                    self.all_items.append({
                        "æ ‡é¢˜": model_name,
                        "å†…å®¹": desc,
                        "æ—¥æœŸ": self.today.isoformat(),
                        "æ¥æº": "ModelScope",
                        "æ¿å—": "ModelScopeçƒ­é—¨",
                        "é“¾æ¥": f"https://modelscope.cn/models/{model_name}",
                        "é¢å¤–": f"ğŸ“¥ {downloads:,} ä¸‹è½½"
                    })
                    count += 1
                
                if count > 0:
                    print(f"  âœ… {count} æ¡ï¼ˆä½¿ç”¨ {url.split('/')[2]}ï¼‰")
                    return  # æˆåŠŸå°±é€€å‡º
                    
            except Exception as e:
                print(f"      âŒ {url.split('/')[2]} -> {type(e).__name__}: {str(e)[:100]}")
                continue
        
        print("  âš ï¸ æ‰€æœ‰æ¥å£å‡å¤±è´¥ï¼ˆModelScope å¯èƒ½éœ€è¦ç™»å½•æˆ–åœ¨å›½å¤–è®¿é—®å—é™ï¼‰")

    # ==================== GitHub AI Agent/MCP/Skills çƒ­é—¨ï¼ˆæ— éœ€ APIï¼‰====================
    
    def fetch_github_agents(self):
        """è·å– GitHub çƒ­é—¨ AI Agent é¡¹ç›®"""
        print("\nğŸ¤– GitHub AI Agent çƒ­é—¨é¡¹ç›®...")
        
        try:
            # æœç´¢ AI agent ç›¸å…³çš„çƒ­é—¨ä»“åº“
            # ä½¿ç”¨æ›´ç®€å•çš„æŸ¥è¯¢æ ¼å¼ï¼Œé¿å… URL ç¼–ç é—®é¢˜
            r = requests.get(
                "https://api.github.com/search/repositories",
                params={
                    "q": "ai agent llm autonomous stars:>1000",
                    "sort": "stars",
                    "order": "desc",
                    "per_page": 10
                },
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=30
            )
            
            if r.status_code != 200:
                print(f"  âŒ HTTP {r.status_code}")
                return
            
            data = r.json()
            repos = data.get("items", [])
            
            count = 0
            for repo in repos[:10]:
                full_name = repo.get("full_name", "")
                if not full_name:
                    continue
                
                self.all_items.append({
                    "æ ‡é¢˜": full_name,
                    "å†…å®¹": (repo.get("description") or "AI Agent é¡¹ç›®")[:200],
                    "æ—¥æœŸ": self.today.isoformat(),
                    "æ¥æº": "GitHub AI Agent",
                    "æ¿å—": "AI Agentçƒ­é—¨",
                    "é“¾æ¥": repo.get("html_url", f"https://github.com/{full_name}"),
                    "é¢å¤–": f"â­ {repo.get('stargazers_count', 0):,} | ğŸ’» {repo.get('language', 'Unknown')}"
                })
                count += 1
            
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {type(e).__name__}: {str(e)[:100]}")
    
    def fetch_github_mcp_tools(self):
        """è·å– Smithery.ai çƒ­é—¨ MCP å·¥å…·"""
        print("\nğŸ”§ Smithery.ai MCP å·¥å…·çƒ­é—¨...")
        
        try:
            # ä½¿ç”¨ Smithery.ai å®˜æ–¹ API è·å–çƒ­é—¨ MCP servers
            r = requests.get(
                "https://registry.smithery.ai/servers?limit=10",
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=30
            )
            
            if r.status_code != 200:
                print(f"  âŒ HTTP {r.status_code}")
                return
            
            data = r.json()
            servers = data.get("servers", [])
            
            count = 0
            for server in servers[:10]:
                name = server.get("displayName", "") or server.get("qualifiedName", "")
                if not name:
                    continue
                
                use_count = server.get("useCount", 0)
                desc = server.get("description", "MCP Server")
                
                self.all_items.append({
                    "æ ‡é¢˜": name,
                    "å†…å®¹": desc[:200] if desc else "MCP å·¥å…·",
                    "æ—¥æœŸ": self.today.isoformat(),
                    "æ¥æº": "Smithery.ai",
                    "æ¿å—": "MCPå·¥å…·çƒ­é—¨",
                    "é“¾æ¥": server.get("homepage", f"https://smithery.ai/server/{server.get('qualifiedName', '')}"),
                    "é¢å¤–": f"ğŸ”¥ {use_count:,} ä½¿ç”¨æ¬¡æ•° | {'âœ… å®˜æ–¹éªŒè¯' if server.get('verified') else ''}"
                })
                count += 1
            
            print(f"  âœ… {count} æ¡")
        except Exception as e:
            print(f"  âŒ {type(e).__name__}: {str(e)[:100]}")
    
    def fetch_github_ai_skills(self):
        """è·å–çƒ­é—¨ AI Skillsï¼ˆä¼˜å…ˆ Smithery APIï¼Œå¤‡ç”¨ skillsmp.com å’Œ GitHubï¼‰"""
        print("\nğŸ¯ çƒ­é—¨ AI Skills...")
        
        count = 0
        smithery_key = os.environ.get("SMITHERY_API_KEY")
        
        # æ–¹æ¡ˆ1: Smithery APIï¼ˆéœ€è¦ API Keyï¼‰
        if smithery_key:
            try:
                r = requests.get(
                    "https://registry.smithery.ai/skills",
                    params={"limit": 10},
                    headers={
                        "Authorization": f"Bearer {smithery_key}",
                        "User-Agent": "Mozilla/5.0"
                    },
                    timeout=30
                )
                
                if r.status_code == 200:
                    data = r.json()
                    skills = data.get("skills", []) if isinstance(data, dict) else data
                    
                    for skill in skills[:10]:
                        name = skill.get("displayName", "") or skill.get("name", "") or skill.get("qualifiedName", "")
                        if not name:
                            continue
                        
                        use_count = skill.get("useCount", 0)
                        desc = skill.get("description", "AI Skill")
                        
                        self.all_items.append({
                            "æ ‡é¢˜": name,
                            "å†…å®¹": desc[:200] if desc else "AI Skill",
                            "æ—¥æœŸ": self.today.isoformat(),
                            "æ¥æº": "Smithery Skills",
                            "æ¿å—": "AI Skillsçƒ­é—¨",
                            "é“¾æ¥": skill.get("homepage", f"https://smithery.ai/skill/{skill.get('qualifiedName', '')}"),
                            "é¢å¤–": f"ğŸ”¥ {use_count:,} ä½¿ç”¨æ¬¡æ•° | {'âœ… å®˜æ–¹éªŒè¯' if skill.get('verified') else ''}"
                        })
                        count += 1
                    
                    if count > 0:
                        print(f"  âœ… {count} æ¡ï¼ˆæ¥è‡ª Smithery APIï¼‰")
                        return
                else:
                    print(f"  âš ï¸ Smithery API HTTP {r.status_code}ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
            except Exception as e:
                print(f"  âš ï¸ Smithery API å¤±è´¥: {type(e).__name__}ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
        else:
            print("  âš ï¸ æœªé…ç½® SMITHERY_API_KEYï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
        
        # æ–¹æ¡ˆ2: å°è¯• skillsmp.comï¼ˆGitHub Actions ç¯å¢ƒåº”å¯è®¿é—®ï¼‰
        try:
            r = requests.get(
                "https://skillsmp.com/api/skills",
                params={"limit": 10, "sort": "popular"},
                headers={
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                    "Accept": "application/json"
                },
                timeout=30
            )
            
            if r.status_code == 200:
                data = r.json()
                skills = data if isinstance(data, list) else data.get("skills", []) or data.get("data", [])
                
                for skill in skills[:10]:
                    name = skill.get("name", "") or skill.get("title", "")
                    if not name:
                        continue
                    
                    self.all_items.append({
                        "æ ‡é¢˜": name,
                        "å†…å®¹": (skill.get("description") or "AI Skill")[:200],
                        "æ—¥æœŸ": self.today.isoformat(),
                        "æ¥æº": "SkillsMP",
                        "æ¿å—": "AI Skillsçƒ­é—¨",
                        "é“¾æ¥": skill.get("url") or skill.get("link") or f"https://skillsmp.com/skill/{skill.get('id', '')}",
                        "é¢å¤–": f"ğŸ”¥ {skill.get('downloads', 0) or skill.get('uses', 0):,} ä½¿ç”¨"
                    })
                    count += 1
                
                if count > 0:
                    print(f"  âœ… {count} æ¡ï¼ˆæ¥è‡ª skillsmp.comï¼‰")
                    return
            else:
                print(f"  âš ï¸ skillsmp.com HTTP {r.status_code}ï¼Œå°è¯• GitHub å¤‡ç”¨æ–¹æ¡ˆ")
        except Exception as e:
            print(f"  âš ï¸ skillsmp.com å¤±è´¥: {type(e).__name__}ï¼Œå°è¯• GitHub å¤‡ç”¨æ–¹æ¡ˆ")
        
        # æ–¹æ¡ˆ2: GitHub å¤‡ç”¨ - æœç´¢ agent skills ç›¸å…³é¡¹ç›®
        try:
            r = requests.get(
                "https://api.github.com/search/repositories",
                params={
                    "q": "awesome-chatgpt-prompts awesome-prompts prompt-engineering stars:>1000",
                    "sort": "stars",
                    "order": "desc",
                    "per_page": 10
                },
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=30
            )
            
            if r.status_code != 200:
                print(f"  âŒ GitHub å¤‡ç”¨ä¹Ÿå¤±è´¥: HTTP {r.status_code}")
                return
            
            data = r.json()
            repos = data.get("items", [])
            
            for repo in repos[:10]:
                full_name = repo.get("full_name", "")
                if not full_name:
                    continue
                
                self.all_items.append({
                    "æ ‡é¢˜": full_name,
                    "å†…å®¹": (repo.get("description") or "AI Skills é¡¹ç›®")[:200],
                    "æ—¥æœŸ": self.today.isoformat(),
                    "æ¥æº": "GitHub Skills",
                    "æ¿å—": "AI Skillsçƒ­é—¨",
                    "é“¾æ¥": repo.get("html_url", f"https://github.com/{full_name}"),
                    "é¢å¤–": f"â­ {repo.get('stargazers_count', 0):,} | ğŸ’» {repo.get('language', 'Unknown')}"
                })
                count += 1
            
            print(f"  âœ… {count} æ¡ï¼ˆæ¥è‡ª GitHub å¤‡ç”¨ï¼‰")
        except Exception as e:
            print(f"  âŒ {type(e).__name__}: {str(e)[:100]}")

    # ==================== AI å¤„ç† ====================
    
    def clean_json(self, text):
        """æ¸…æ´—å¹¶æå–æœ‰æ•ˆçš„ JSON"""
        import re
        text = text.strip()
        
        # 1. ç§»é™¤ Markdown ä»£ç å—
        if "```" in text:
            pattern = r"```(?:json|JSON)?\s*([\s\S]*?)\s*```"
            match = re.search(pattern, text)
            if match:
                text = match.group(1).strip()
                
        # 2. å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(text)
        except:
            pass
    
        # 3. ä¿®å¤å¸¸è§é”™è¯¯
        # ç§»é™¤å¯¹è±¡/æ•°ç»„æœ«å°¾çš„é€—å·
        text = re.sub(r",\s*}", "}", text)
        text = re.sub(r",\s*]", "]", text)
        
        # å°è¯•è§£æ
        try:
            return json.loads(text)
        except:
            pass
            
        # 4. æå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„ JSON å¯¹è±¡/æ•°ç»„ï¼ˆå¯»æ‰¾åŒ¹é…çš„æ‹¬å·ï¼‰
        stack = []
        start_index = -1
        
        for i, char in enumerate(text):
            if char == '{' or char == '[':
                if not stack:
                    start_index = i
                stack.append(char)
            elif char == '}' or char == ']':
                if stack:
                    last = stack[-1]
                    if (char == '}' and last == '{') or (char == ']' and last == '['):
                        stack.pop()
                        if not stack:
                            # æ‰¾åˆ°ä¸€ä¸ªå®Œæ•´çš„å—
                            candidate = text[start_index:i+1]
                            try:
                                return json.loads(candidate)
                            except:
                                pass
        return None

    def ai_process(self):
        """AI ç¿»è¯‘å’Œæ‘˜è¦ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰"""
        if not self.siliconflow_key:
            error_msg = "âŒ æœªé…ç½® SILICONFLOW_API_KEYï¼Œæ— æ³•è¿›è¡Œ AI å¤„ç†"
            print(f"\n{error_msg}")
            
            # ä¿å­˜é”™è¯¯ä¿¡æ¯ï¼ˆé™åˆ¶5æ¡ï¼‰
            fallback = {
                "date": self.today_str,
                "error": error_msg,
                "categories": {"åŸå§‹æ•°æ®": self.all_items[:5]},
                "analysis": {
                    "summary": "âš ï¸ æœªé…ç½® API Keyï¼Œè¯·åœ¨ GitHub Secrets ä¸­æ·»åŠ  SILICONFLOW_API_KEYï¼ˆæ˜¾ç¤ºå‰5æ¡ï¼‰",
                    "trends": []
                }
            }
            (self.data_dir / "latest.json").write_text(
                json.dumps(fallback, ensure_ascii=False, indent=2), encoding="utf-8")
            return fallback
        
        if not self.all_items:
            print("\nâš ï¸ æ²¡æœ‰æ•°æ®")
            return None
        
        print(f"\nğŸ¤– AI å¤„ç† ({self.model})...")
        
        try:
            # 1. é¢„å¤„ç†ï¼šæŒ‰åˆ†ç±»åˆ†ç»„å¹¶é™åˆ¶æ•°é‡ï¼ˆå‡å°‘è¾“å…¥ tokenï¼‰
            # æ¯ä¸ªåˆ†ç±»æœ€å¤šå–å‰15æ¡å‘ç»™ AI ç­›é€‰
            grouped = {}
            for item in self.all_items:
                cat = item.get("æ¿å—", "å…¶ä»–")
                if cat not in grouped:
                    grouped[cat] = []
                if len(grouped[cat]) < 15:
                    grouped[cat].append(item)
            
            filtered_items = []
            for items in grouped.values():
                filtered_items.extend(items)
                
            print(f"  æ— éœ€å¤„ç†çš„æ•°æ®: {len(self.all_items) - len(filtered_items)} æ¡ (æ¯ç±»é™åˆ¶15æ¡è¾“å…¥)")
            
            # 2. åˆ†æ‰¹å¤„ç†
            print(f"  æ— éœ€å¤„ç†çš„æ•°æ®: {len(self.all_items) - len(filtered_items)} æ¡ (æ¯ç±»é™åˆ¶15æ¡è¾“å…¥)")
            
            # 2. åˆ†æ‰¹å¤„ç†
            BATCH_SIZE = 15  # é™ä½ Batch Size é˜²æ­¢æˆªæ–­
            batches = [filtered_items[i:i + BATCH_SIZE] for i in range(0, len(filtered_items), BATCH_SIZE)]
            
            final_categories = {}
            final_analysis = {"summary": "ä»Šæ—¥ AI æ‘˜è¦", "trends": []}
            
            from openai import OpenAI
            client = OpenAI(
                api_key=self.siliconflow_key,
                base_url="https://api.siliconflow.cn/v1"
            )

            for i, batch in enumerate(batches):
                print(f"  ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i+1}/{len(batches)} ({len(batch)} æ¡)...")
                
                prompt = f"""You are a JSON formatter. Process the following AI news data and return ONLY valid JSON.

Input data:
{json.dumps(batch, ensure_ascii=False)}

Requirements:
1. Translate English to Chinese
2. Summarize content to 60-80 Chinese characters
3. Group by category
4. Keep "é¢å¤–" field
5. JSON Output ONLY.

Output Format:
{{"categories":{{"CategoryName":[{{ "æ ‡é¢˜":"...", "å†…å®¹":"...", "é“¾æ¥":"...", "æ—¥æœŸ":"...", "æ¥æº":"...", "é¢å¤–":"..." }}]}}, "analysis":{{"summary":"...", "trends":["..."]}}}}
"""

                try:
                    resp = client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "You are a JSON formatter. Return valid JSON only."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=8192,
                        temperature=0.1
                    )
                    
                    content = resp.choices[0].message.content.strip()
                    
                    # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æ
                    batch_result = self.clean_json(content)
                    
                    if not batch_result:
                        print(f"  âŒ æ‰¹æ¬¡ {i+1} è§£æå½»åº•å¤±è´¥ï¼ŒåŸå§‹å†…å®¹é¢„è§ˆ: {content[:100]}...")
                        continue

                    # åˆå¹¶ç»“æœ
                    if batch_result:
                        # åˆå¹¶åˆ†ç±»
                        cats = batch_result.get("categories", {})
                        for cat_name, items in cats.items():
                            if cat_name not in final_categories:
                                final_categories[cat_name] = []
                            final_categories[cat_name].extend(items)
                        
                        # ä»…ä½¿ç”¨ç¬¬ä¸€æ‰¹çš„åˆ†æç»“æœï¼ˆé€šå¸¸åŒ…å«æ–°é—»ï¼‰
                        if i == 0 and "analysis" in batch_result:
                            final_analysis = batch_result["analysis"]
                            
                except Exception as e:
                    print(f"  âŒ æ‰¹æ¬¡ {i+1} è¯·æ±‚å¤±è´¥: {e}")

            # 3. æœ€ç»ˆç»„è£…
            result = {
                "date": self.today_str,
                "categories": final_categories,
                "analysis": final_analysis
            }
            
            # å†æ¬¡ç¡®ä¿æ¯ç±»ä¸è¶…è¿‡10æ¡
            total = 0
            for cat in result["categories"]:
                result["categories"][cat] = result["categories"][cat][:10]
                total += len(result["categories"][cat])
            
            # ä¿å­˜
            (self.data_dir / f"digest_{self.today_str}.json").write_text(
                json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
            (self.data_dir / "latest.json").write_text(
                json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
            
            total = sum(len(v) for v in result.get("categories", {}).values())
            print(f"  âœ… å®Œæˆï¼Œå…± {total} æ¡ï¼ˆæ¯åˆ†ç±»æœ€å¤š10æ¡ï¼‰")
            return result
            
        except Exception as e:
            import traceback
            error_msg = f"AI å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
            print(f"  âŒ {error_msg}")
            
            # å¤±è´¥æ—¶ä¿å­˜åŸå§‹æ•°æ®ï¼Œå¹¶é™„å¸¦é”™è¯¯ä¿¡æ¯ï¼ˆé™åˆ¶5æ¡ï¼‰
            fallback = {
                "date": self.today_str,
                "error": error_msg,
                "categories": {"åŸå§‹æ•°æ®": self.all_items[:5]},
                "analysis": {
                    "summary": f"âš ï¸ AI å¤„ç†å¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹æ•°æ®ï¼ˆå‰5æ¡ï¼‰ã€‚é”™è¯¯ï¼š{str(e)}",
                    "trends": []
                }
            }
            (self.data_dir / "latest.json").write_text(
                json.dumps(fallback, ensure_ascii=False, indent=2), encoding="utf-8")
            return fallback

    def run(self):
        print("=" * 50)
        print(f"ğŸš€ AI èµ„è®¯èšåˆå™¨ - {self.today_str}")
        print("=" * 50)
        
        # æ•°æ®é‡‡é›†ï¼ˆæ¯ä¸ªç‹¬ç«‹ï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–ï¼‰
        self.safe_fetch("RSS", self.fetch_rss)
        self.safe_fetch("YouTubeåšä¸»", self.fetch_youtube_rss)
        self.safe_fetch("YouTubeçƒ­é—¨", self.fetch_youtube_trending)
        self.safe_fetch("Twitterçƒ­é—¨", self.fetch_twitter)
        self.safe_fetch("Twitterè´¦å·", self.fetch_twitter_accounts)
        self.safe_fetch("TikTok", self.fetch_tiktok)
        self.safe_fetch("GitHubçƒ­é—¨", self.fetch_github_trending)
        self.safe_fetch("AI Agentçƒ­é—¨", self.fetch_github_agents)
        self.safe_fetch("MCPå·¥å…·çƒ­é—¨", self.fetch_github_mcp_tools)
        self.safe_fetch("AI Skillsçƒ­é—¨", self.fetch_github_ai_skills)
        self.safe_fetch("HuggingFace", self.fetch_huggingface_trending)
        self.safe_fetch("ModelScope", self.fetch_modelscope_trending)
        
        print(f"\nğŸ“¦ å…±é‡‡é›† {len(self.all_items)} æ¡")
        
        # AI å¤„ç†
        result = self.ai_process()
        
        print("\n" + "=" * 50)
        print("âœ¨ å®Œæˆ!")
        return result


if __name__ == "__main__":
    AIDigestGenerator().run()
